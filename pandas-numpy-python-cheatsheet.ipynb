{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"230px"},"toc_section_display":true,"toc_window_display":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro\n\nI assembled a super quick cheatsheet of the most common Pandas, Numpy and Python tasks I tend to do. Let me know if I missed anything important in the comments below!\n\n## If you like this kernel, please give it an upvote. Thank you! :)\n\n<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Structures\" data-toc-modified-id=\"Data-Structures-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Structures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lists[]\" data-toc-modified-id=\"Lists[]-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Lists[]</a></span><ul class=\"toc-item\"><li><span><a href=\"#List-Comprehensions---(do..-for)\" data-toc-modified-id=\"List-Comprehensions---(do..-for)-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>List Comprehensions - (do.. for)</a></span></li><li><span><a href=\"#adding-conditionals-(do..-for..-if)\" data-toc-modified-id=\"adding-conditionals-(do..-for..-if)-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>adding conditionals (do.. for.. if)</a></span></li><li><span><a href=\"#examples\" data-toc-modified-id=\"examples-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>examples</a></span></li><li><span><a href=\"#Lambda-Functions\" data-toc-modified-id=\"Lambda-Functions-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Lambda Functions</a></span></li><li><span><a href=\"#map()---apply-lambda-function-to-a-list\" data-toc-modified-id=\"map()---apply-lambda-function-to-a-list-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>map() - apply lambda function to a list</a></span></li><li><span><a href=\"#filter()---apply-lambda-function-to-a-list\" data-toc-modified-id=\"filter()---apply-lambda-function-to-a-list-1.1.6\"><span class=\"toc-item-num\">1.1.6&nbsp;&nbsp;</span>filter() - apply lambda function to a list</a></span></li><li><span><a href=\"#Generators\" data-toc-modified-id=\"Generators-1.1.7\"><span class=\"toc-item-num\">1.1.7&nbsp;&nbsp;</span>Generators</a></span></li><li><span><a href=\"#create-list\" data-toc-modified-id=\"create-list-1.1.8\"><span class=\"toc-item-num\">1.1.8&nbsp;&nbsp;</span>create list</a></span></li><li><span><a href=\"#access-list-elements\" data-toc-modified-id=\"access-list-elements-1.1.9\"><span class=\"toc-item-num\">1.1.9&nbsp;&nbsp;</span>access list elements</a></span></li><li><span><a href=\"#slicing-[,)\" data-toc-modified-id=\"slicing-[,)-1.1.10\"><span class=\"toc-item-num\">1.1.10&nbsp;&nbsp;</span>slicing [,)</a></span></li><li><span><a href=\"#in,-not-in\" data-toc-modified-id=\"in,-not-in-1.1.11\"><span class=\"toc-item-num\">1.1.11&nbsp;&nbsp;</span>in, not in</a></span></li><li><span><a href=\"#Mutable-and-ordered\" data-toc-modified-id=\"Mutable-and-ordered-1.1.12\"><span class=\"toc-item-num\">1.1.12&nbsp;&nbsp;</span>Mutable and ordered</a></span></li><li><span><a href=\"#length-of-list\" data-toc-modified-id=\"length-of-list-1.1.13\"><span class=\"toc-item-num\">1.1.13&nbsp;&nbsp;</span>length of list</a></span></li><li><span><a href=\"#smallest-and-greatest-element-in-list\" data-toc-modified-id=\"smallest-and-greatest-element-in-list-1.1.14\"><span class=\"toc-item-num\">1.1.14&nbsp;&nbsp;</span>smallest and greatest element in list</a></span></li><li><span><a href=\"#sort-list\" data-toc-modified-id=\"sort-list-1.1.15\"><span class=\"toc-item-num\">1.1.15&nbsp;&nbsp;</span>sort list</a></span></li><li><span><a href=\"#join()\" data-toc-modified-id=\"join()-1.1.16\"><span class=\"toc-item-num\">1.1.16&nbsp;&nbsp;</span>join()</a></span></li><li><span><a href=\"#Creating-a-new-list\" data-toc-modified-id=\"Creating-a-new-list-1.1.17\"><span class=\"toc-item-num\">1.1.17&nbsp;&nbsp;</span>Creating a new list</a></span></li><li><span><a href=\"#Adding-an-element-to-the-end-of-a-list---append()\" data-toc-modified-id=\"Adding-an-element-to-the-end-of-a-list---append()-1.1.18\"><span class=\"toc-item-num\">1.1.18&nbsp;&nbsp;</span>Adding an element to the end of a list - append()</a></span></li><li><span><a href=\"#Modifying-a-new-list\" data-toc-modified-id=\"Modifying-a-new-list-1.1.19\"><span class=\"toc-item-num\">1.1.19&nbsp;&nbsp;</span>Modifying a new list</a></span></li><li><span><a href=\"#Print-a-formatted-string-from-parameters-in-list\" data-toc-modified-id=\"Print-a-formatted-string-from-parameters-in-list-1.1.20\"><span class=\"toc-item-num\">1.1.20&nbsp;&nbsp;</span>Print a formatted string from parameters in list</a></span></li><li><span><a href=\"#Convert-an-iterable-(tuple,-string,-set,-dictionary)-to-a-list---list()\" data-toc-modified-id=\"Convert-an-iterable-(tuple,-string,-set,-dictionary)-to-a-list---list()-1.1.21\"><span class=\"toc-item-num\">1.1.21&nbsp;&nbsp;</span>Convert an iterable (tuple, string, set, dictionary) to a list - list()</a></span></li></ul></li><li><span><a href=\"#Tuples()\" data-toc-modified-id=\"Tuples()-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Tuples()</a></span><ul class=\"toc-item\"><li><span><a href=\"#create-tuple\" data-toc-modified-id=\"create-tuple-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>create tuple</a></span></li><li><span><a href=\"#access-tuple\" data-toc-modified-id=\"access-tuple-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>access tuple</a></span></li><li><span><a href=\"#tuple-packing\" data-toc-modified-id=\"tuple-packing-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>tuple packing</a></span></li><li><span><a href=\"#tuple-unpacking\" data-toc-modified-id=\"tuple-unpacking-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>tuple unpacking</a></span></li></ul></li><li><span><a href=\"#Sets{}\" data-toc-modified-id=\"Sets{}-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Sets{}</a></span><ul class=\"toc-item\"><li><span><a href=\"#create-sets\" data-toc-modified-id=\"create-sets-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>create sets</a></span></li><li><span><a href=\"#check-for-element\" data-toc-modified-id=\"check-for-element-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>check for element</a></span></li><li><span><a href=\"#add-an-element\" data-toc-modified-id=\"add-an-element-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>add an element</a></span></li><li><span><a href=\"#remove-a-random-element\" data-toc-modified-id=\"remove-a-random-element-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>remove a random element</a></span></li></ul></li><li><span><a href=\"#Dicts{}\" data-toc-modified-id=\"Dicts{}-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Dicts{}</a></span><ul class=\"toc-item\"><li><span><a href=\"#create-dict\" data-toc-modified-id=\"create-dict-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>create dict</a></span></li><li><span><a href=\"#accessing-an-element's-value\" data-toc-modified-id=\"accessing-an-element's-value-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>accessing an element's value</a></span></li><li><span><a href=\"#adding-elements\" data-toc-modified-id=\"adding-elements-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>adding elements</a></span></li><li><span><a href=\"#Iterating-through-a-dictionary\" data-toc-modified-id=\"Iterating-through-a-dictionary-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Iterating through a dictionary</a></span></li><li><span><a href=\"#check-whether-a-value-is-in-a-dictionary\" data-toc-modified-id=\"check-whether-a-value-is-in-a-dictionary-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;</span>check whether a value is in a dictionary</a></span></li><li><span><a href=\"#get()-looks-up-values-in-a-dictionary\" data-toc-modified-id=\"get()-looks-up-values-in-a-dictionary-1.4.6\"><span class=\"toc-item-num\">1.4.6&nbsp;&nbsp;</span>get() looks up values in a dictionary</a></span></li><li><span><a href=\"#Identity-Operators\" data-toc-modified-id=\"Identity-Operators-1.4.7\"><span class=\"toc-item-num\">1.4.7&nbsp;&nbsp;</span>Identity Operators</a></span></li><li><span><a href=\"#Equality-(==)-and-identity-(is)\" data-toc-modified-id=\"Equality-(==)-and-identity-(is)-1.4.8\"><span class=\"toc-item-num\">1.4.8&nbsp;&nbsp;</span>Equality (==) and identity (is)</a></span></li><li><span><a href=\"#Compound-Data-Structures\" data-toc-modified-id=\"Compound-Data-Structures-1.4.9\"><span class=\"toc-item-num\">1.4.9&nbsp;&nbsp;</span>Compound Data Structures</a></span></li><li><span><a href=\"#Dict-frequency-counter\" data-toc-modified-id=\"Dict-frequency-counter-1.4.10\"><span class=\"toc-item-num\">1.4.10&nbsp;&nbsp;</span>Dict frequency counter</a></span></li></ul></li></ul></li><li><span><a href=\"#Numpy\" data-toc-modified-id=\"Numpy-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Numpy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-ndarray\" data-toc-modified-id=\"Create-ndarray-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Create ndarray</a></span></li><li><span><a href=\"#Create-ndarray-with-dtype\" data-toc-modified-id=\"Create-ndarray-with-dtype-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Create ndarray with dtype</a></span></li><li><span><a href=\"#Save-and-load\" data-toc-modified-id=\"Save-and-load-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Save and load</a></span></li><li><span><a href=\"#Zeros\" data-toc-modified-id=\"Zeros-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Zeros</a></span></li><li><span><a href=\"#Ones\" data-toc-modified-id=\"Ones-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Ones</a></span></li><li><span><a href=\"#Full\" data-toc-modified-id=\"Full-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Full</a></span></li><li><span><a href=\"#Identity-Matrix\" data-toc-modified-id=\"Identity-Matrix-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Identity Matrix</a></span></li><li><span><a href=\"#Diagonal-Matrix\" data-toc-modified-id=\"Diagonal-Matrix-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Diagonal Matrix</a></span></li><li><span><a href=\"#Arange\" data-toc-modified-id=\"Arange-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>Arange</a></span></li><li><span><a href=\"#Linspace\" data-toc-modified-id=\"Linspace-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>Linspace</a></span></li><li><span><a href=\"#Reshape\" data-toc-modified-id=\"Reshape-2.11\"><span class=\"toc-item-num\">2.11&nbsp;&nbsp;</span>Reshape</a></span></li><li><span><a href=\"#Slicing\" data-toc-modified-id=\"Slicing-2.12\"><span class=\"toc-item-num\">2.12&nbsp;&nbsp;</span>Slicing</a></span></li><li><span><a href=\"#Random\" data-toc-modified-id=\"Random-2.13\"><span class=\"toc-item-num\">2.13&nbsp;&nbsp;</span>Random</a></span></li><li><span><a href=\"#Mutability\" data-toc-modified-id=\"Mutability-2.14\"><span class=\"toc-item-num\">2.14&nbsp;&nbsp;</span>Mutability</a></span></li><li><span><a href=\"#Delete\" data-toc-modified-id=\"Delete-2.15\"><span class=\"toc-item-num\">2.15&nbsp;&nbsp;</span>Delete</a></span></li><li><span><a href=\"#Append\" data-toc-modified-id=\"Append-2.16\"><span class=\"toc-item-num\">2.16&nbsp;&nbsp;</span>Append</a></span></li><li><span><a href=\"#Insert\" data-toc-modified-id=\"Insert-2.17\"><span class=\"toc-item-num\">2.17&nbsp;&nbsp;</span>Insert</a></span></li><li><span><a href=\"#Stacking\" data-toc-modified-id=\"Stacking-2.18\"><span class=\"toc-item-num\">2.18&nbsp;&nbsp;</span>Stacking</a></span></li><li><span><a href=\"#Copy\" data-toc-modified-id=\"Copy-2.19\"><span class=\"toc-item-num\">2.19&nbsp;&nbsp;</span>Copy</a></span></li><li><span><a href=\"#Extract-elements-along-the-diagonal\" data-toc-modified-id=\"Extract-elements-along-the-diagonal-2.20\"><span class=\"toc-item-num\">2.20&nbsp;&nbsp;</span>Extract elements along the diagonal</a></span></li><li><span><a href=\"#Find-Unique-Elements\" data-toc-modified-id=\"Find-Unique-Elements-2.21\"><span class=\"toc-item-num\">2.21&nbsp;&nbsp;</span>Find Unique Elements</a></span></li><li><span><a href=\"#Boolean-Indexing\" data-toc-modified-id=\"Boolean-Indexing-2.22\"><span class=\"toc-item-num\">2.22&nbsp;&nbsp;</span>Boolean Indexing</a></span></li><li><span><a href=\"#Set-Operations\" data-toc-modified-id=\"Set-Operations-2.23\"><span class=\"toc-item-num\">2.23&nbsp;&nbsp;</span>Set Operations</a></span></li><li><span><a href=\"#Sorting\" data-toc-modified-id=\"Sorting-2.24\"><span class=\"toc-item-num\">2.24&nbsp;&nbsp;</span>Sorting</a></span></li><li><span><a href=\"#Math-Functions\" data-toc-modified-id=\"Math-Functions-2.25\"><span class=\"toc-item-num\">2.25&nbsp;&nbsp;</span>Math Functions</a></span></li><li><span><a href=\"#Statistical-Functions\" data-toc-modified-id=\"Statistical-Functions-2.26\"><span class=\"toc-item-num\">2.26&nbsp;&nbsp;</span>Statistical Functions</a></span></li><li><span><a href=\"#Broadcasting\" data-toc-modified-id=\"Broadcasting-2.27\"><span class=\"toc-item-num\">2.27&nbsp;&nbsp;</span>Broadcasting</a></span></li></ul></li><li><span><a href=\"#Pandas\" data-toc-modified-id=\"Pandas-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series\" data-toc-modified-id=\"Series-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Series</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Series\" data-toc-modified-id=\"Create-Series-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Create Series</a></span></li><li><span><a href=\"#shape,-size,-values,-index,-ndim\" data-toc-modified-id=\"shape,-size,-values,-index,-ndim-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>shape, size, values, index, ndim</a></span></li><li><span><a href=\"#check-whether-an-index-label-exists-in-Series\" data-toc-modified-id=\"check-whether-an-index-label-exists-in-Series-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>check whether an index label exists in Series</a></span></li><li><span><a href=\"#Accessing-Elements\" data-toc-modified-id=\"Accessing-Elements-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Accessing Elements</a></span></li><li><span><a href=\"#Change-Elements\" data-toc-modified-id=\"Change-Elements-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Change Elements</a></span></li><li><span><a href=\"#Delete-Elements\" data-toc-modified-id=\"Delete-Elements-3.1.6\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Delete Elements</a></span></li><li><span><a href=\"#Arithmetic-Operations\" data-toc-modified-id=\"Arithmetic-Operations-3.1.7\"><span class=\"toc-item-num\">3.1.7&nbsp;&nbsp;</span>Arithmetic Operations</a></span></li></ul></li><li><span><a href=\"#Dataframe\" data-toc-modified-id=\"Dataframe-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Dataframe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Axes\" data-toc-modified-id=\"Axes-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Axes</a></span></li><li><span><a href=\"#Loading-Data-into-DF\" data-toc-modified-id=\"Loading-Data-into-DF-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Loading Data into DF</a></span></li><li><span><a href=\"#Create-Dataframe\" data-toc-modified-id=\"Create-Dataframe-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Create Dataframe</a></span></li><li><span><a href=\"#Create-df-from-Series,-dicts\" data-toc-modified-id=\"Create-df-from-Series,-dicts-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Create df from Series, dicts</a></span></li><li><span><a href=\"#Access-Elements\" data-toc-modified-id=\"Access-Elements-3.2.5\"><span class=\"toc-item-num\">3.2.5&nbsp;&nbsp;</span>Access Elements</a></span></li><li><span><a href=\"#Modify-Elements\" data-toc-modified-id=\"Modify-Elements-3.2.6\"><span class=\"toc-item-num\">3.2.6&nbsp;&nbsp;</span>Modify Elements</a></span></li><li><span><a href=\"#Delete-Element\" data-toc-modified-id=\"Delete-Element-3.2.7\"><span class=\"toc-item-num\">3.2.7&nbsp;&nbsp;</span>Delete Element</a></span></li><li><span><a href=\"#Rename-the-row-and-column-labels\" data-toc-modified-id=\"Rename-the-row-and-column-labels-3.2.8\"><span class=\"toc-item-num\">3.2.8&nbsp;&nbsp;</span>Rename the row and column labels</a></span></li><li><span><a href=\"#Change-index\" data-toc-modified-id=\"Change-index-3.2.9\"><span class=\"toc-item-num\">3.2.9&nbsp;&nbsp;</span>Change index</a></span></li><li><span><a href=\"#Dealing-with-NaN-values-(missing-data)\" data-toc-modified-id=\"Dealing-with-NaN-values-(missing-data)-3.2.10\"><span class=\"toc-item-num\">3.2.10&nbsp;&nbsp;</span>Dealing with NaN values (missing data)</a></span></li><li><span><a href=\"#head,-tail,-describe,-max,-memory_usage\" data-toc-modified-id=\"head,-tail,-describe,-max,-memory_usage-3.2.11\"><span class=\"toc-item-num\">3.2.11&nbsp;&nbsp;</span>head, tail, describe, max, memory_usage</a></span></li><li><span><a href=\"#corr\" data-toc-modified-id=\"corr-3.2.12\"><span class=\"toc-item-num\">3.2.12&nbsp;&nbsp;</span>corr</a></span></li><li><span><a href=\"#Groupby\" data-toc-modified-id=\"Groupby-3.2.13\"><span class=\"toc-item-num\">3.2.13&nbsp;&nbsp;</span>Groupby</a></span></li><li><span><a href=\"#Replace-Values\" data-toc-modified-id=\"Replace-Values-3.2.14\"><span class=\"toc-item-num\">3.2.14&nbsp;&nbsp;</span>Replace Values</a></span></li><li><span><a href=\"#Reading-Files\" data-toc-modified-id=\"Reading-Files-3.2.15\"><span class=\"toc-item-num\">3.2.15&nbsp;&nbsp;</span>Reading Files</a></span></li><li><span><a href=\"#Summarizing\" data-toc-modified-id=\"Summarizing-3.2.16\"><span class=\"toc-item-num\">3.2.16&nbsp;&nbsp;</span>Summarizing</a></span></li><li><span><a href=\"#Working-with-Columns\" data-toc-modified-id=\"Working-with-Columns-3.2.17\"><span class=\"toc-item-num\">3.2.17&nbsp;&nbsp;</span>Working with Columns</a></span></li><li><span><a href=\"#Filtering-and-Sorting\" data-toc-modified-id=\"Filtering-and-Sorting-3.2.18\"><span class=\"toc-item-num\">3.2.18&nbsp;&nbsp;</span>Filtering and Sorting</a></span></li><li><span><a href=\"#Sorting\" data-toc-modified-id=\"Sorting-3.2.19\"><span class=\"toc-item-num\">3.2.19&nbsp;&nbsp;</span>Sorting</a></span></li><li><span><a href=\"#Selecting-Multiple-Columns-and-Filtering-Rows\" data-toc-modified-id=\"Selecting-Multiple-Columns-and-Filtering-Rows-3.2.20\"><span class=\"toc-item-num\">3.2.20&nbsp;&nbsp;</span>Selecting Multiple Columns and Filtering Rows</a></span></li><li><span><a href=\"#Renaming,-Adding,-and-Removing-Columns\" data-toc-modified-id=\"Renaming,-Adding,-and-Removing-Columns-3.2.21\"><span class=\"toc-item-num\">3.2.21&nbsp;&nbsp;</span>Renaming, Adding, and Removing Columns</a></span></li><li><span><a href=\"#Lower-case-all-DataFrame-column-names\" data-toc-modified-id=\"Lower-case-all-DataFrame-column-names-3.2.22\"><span class=\"toc-item-num\">3.2.22&nbsp;&nbsp;</span>Lower-case all DataFrame column names</a></span></li><li><span><a href=\"#Handling-Missing-Values\" data-toc-modified-id=\"Handling-Missing-Values-3.2.23\"><span class=\"toc-item-num\">3.2.23&nbsp;&nbsp;</span>Handling Missing Values</a></span></li><li><span><a href=\"#Handling-Duplicated-Values\" data-toc-modified-id=\"Handling-Duplicated-Values-3.2.24\"><span class=\"toc-item-num\">3.2.24&nbsp;&nbsp;</span>Handling Duplicated Values</a></span></li><li><span><a href=\"#Split-Apply-Combine\" data-toc-modified-id=\"Split-Apply-Combine-3.2.25\"><span class=\"toc-item-num\">3.2.25&nbsp;&nbsp;</span>Split-Apply-Combine</a></span></li><li><span><a href=\"#Merging-and-Concatenating-Dataframes\" data-toc-modified-id=\"Merging-and-Concatenating-Dataframes-3.2.26\"><span class=\"toc-item-num\">3.2.26&nbsp;&nbsp;</span>Merging and Concatenating Dataframes</a></span></li><li><span><a href=\"#Frequently-Used-Features\" data-toc-modified-id=\"Frequently-Used-Features-3.2.27\"><span class=\"toc-item-num\">3.2.27&nbsp;&nbsp;</span>Frequently Used Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#map-existing-values-to-a-different-set-of-values\" data-toc-modified-id=\"map-existing-values-to-a-different-set-of-values-3.2.27.1\"><span class=\"toc-item-num\">3.2.27.1&nbsp;&nbsp;</span>map existing values to a different set of values</a></span></li><li><span><a href=\"#encode-strings-as-integer-values-(automatically-starts-at-0)\" data-toc-modified-id=\"encode-strings-as-integer-values-(automatically-starts-at-0)-3.2.27.2\"><span class=\"toc-item-num\">3.2.27.2&nbsp;&nbsp;</span>encode strings as integer values (automatically starts at 0)</a></span></li><li><span><a href=\"#determine-unique-values-in-a-column\" data-toc-modified-id=\"determine-unique-values-in-a-column-3.2.27.3\"><span class=\"toc-item-num\">3.2.27.3&nbsp;&nbsp;</span>determine unique values in a column</a></span></li><li><span><a href=\"#count-the-number-of-unique-values\" data-toc-modified-id=\"count-the-number-of-unique-values-3.2.27.4\"><span class=\"toc-item-num\">3.2.27.4&nbsp;&nbsp;</span>count the number of unique values</a></span></li><li><span><a href=\"#replace-all-instances-of-a-value-in-a-column-(must-match-entire-value)\" data-toc-modified-id=\"replace-all-instances-of-a-value-in-a-column-(must-match-entire-value)-3.2.27.5\"><span class=\"toc-item-num\">3.2.27.5&nbsp;&nbsp;</span>replace all instances of a value in a column (must match entire value)</a></span></li><li><span><a href=\"#alter-values-in-one-column-based-on-values-in-another-column\" data-toc-modified-id=\"alter-values-in-one-column-based-on-values-in-another-column-3.2.27.6\"><span class=\"toc-item-num\">3.2.27.6&nbsp;&nbsp;</span>alter values in one column based on values in another column</a></span></li><li><span><a href=\"#transpose-data-frame-(i.e.-rows-become-columns,-columns-become-rows)\" data-toc-modified-id=\"transpose-data-frame-(i.e.-rows-become-columns,-columns-become-rows)-3.2.27.7\"><span class=\"toc-item-num\">3.2.27.7&nbsp;&nbsp;</span>transpose data frame (i.e. rows become columns, columns become rows)</a></span></li><li><span><a href=\"#string-methods-are-accessed-via-‘str’\" data-toc-modified-id=\"string-methods-are-accessed-via-‘str’-3.2.27.8\"><span class=\"toc-item-num\">3.2.27.8&nbsp;&nbsp;</span>string methods are accessed via ‘str’</a></span></li><li><span><a href=\"#converts-to-uppercase\" data-toc-modified-id=\"converts-to-uppercase-3.2.27.9\"><span class=\"toc-item-num\">3.2.27.9&nbsp;&nbsp;</span>converts to uppercase</a></span></li><li><span><a href=\"#convert-a-string-to-the-datetime_column-format\" data-toc-modified-id=\"convert-a-string-to-the-datetime_column-format-3.2.27.10\"><span class=\"toc-item-num\">3.2.27.10&nbsp;&nbsp;</span>convert a string to the datetime_column format</a></span></li><li><span><a href=\"#datetime_column-format-exposes-convenient-attributes\" data-toc-modified-id=\"datetime_column-format-exposes-convenient-attributes-3.2.27.11\"><span class=\"toc-item-num\">3.2.27.11&nbsp;&nbsp;</span>datetime_column format exposes convenient attributes</a></span></li><li><span><a href=\"#boolean-filtering-with-datetime_column-format\" data-toc-modified-id=\"boolean-filtering-with-datetime_column-format-3.2.27.12\"><span class=\"toc-item-num\">3.2.27.12&nbsp;&nbsp;</span>boolean filtering with datetime_column format</a></span></li><li><span><a href=\"#setting-and-then-removing-an-index,-resetting-index-can-help-remove-hierarchical-indexes-while-preserving-the-table-in-its-basic-structure\" data-toc-modified-id=\"setting-and-then-removing-an-index,-resetting-index-can-help-remove-hierarchical-indexes-while-preserving-the-table-in-its-basic-structure-3.2.27.13\"><span class=\"toc-item-num\">3.2.27.13&nbsp;&nbsp;</span>setting and then removing an index, resetting index can help remove hierarchical indexes while preserving the table in its basic structure</a></span></li><li><span><a href=\"#sort-a-column-by-its-index\" data-toc-modified-id=\"sort-a-column-by-its-index-3.2.27.14\"><span class=\"toc-item-num\">3.2.27.14&nbsp;&nbsp;</span>sort a column by its index</a></span></li><li><span><a href=\"#change-the-data-type-of-a-column\" data-toc-modified-id=\"change-the-data-type-of-a-column-3.2.27.15\"><span class=\"toc-item-num\">3.2.27.15&nbsp;&nbsp;</span>change the data type of a column</a></span></li><li><span><a href=\"#change-the-data-type-of-a-column-when-reading-in-a-file\" data-toc-modified-id=\"change-the-data-type-of-a-column-when-reading-in-a-file-3.2.27.16\"><span class=\"toc-item-num\">3.2.27.16&nbsp;&nbsp;</span>change the data type of a column when reading in a file</a></span></li><li><span><a href=\"#create-dummy-variables-for-‘column_x’-and-exclude-first-dummy-column\" data-toc-modified-id=\"create-dummy-variables-for-‘column_x’-and-exclude-first-dummy-column-3.2.27.17\"><span class=\"toc-item-num\">3.2.27.17&nbsp;&nbsp;</span>create dummy variables for ‘column_x’ and exclude first dummy column</a></span></li><li><span><a href=\"#concatenate-two-DataFrames-(axis=0-for-rows,-axis=1-for-columns)\" data-toc-modified-id=\"concatenate-two-DataFrames-(axis=0-for-rows,-axis=1-for-columns)-3.2.27.18\"><span class=\"toc-item-num\">3.2.27.18&nbsp;&nbsp;</span>concatenate two DataFrames (axis=0 for rows, axis=1 for columns)</a></span></li><li><span><a href=\"#Loop-through-rows-in-a-DataFrame\" data-toc-modified-id=\"Loop-through-rows-in-a-DataFrame-3.2.27.19\"><span class=\"toc-item-num\">3.2.27.19&nbsp;&nbsp;</span>Loop through rows in a DataFrame</a></span></li><li><span><a href=\"#Get-rid-of-non-numeric-values-throughout-a-DataFrame\" data-toc-modified-id=\"Get-rid-of-non-numeric-values-throughout-a-DataFrame-3.2.27.20\"><span class=\"toc-item-num\">3.2.27.20&nbsp;&nbsp;</span>Get rid of non-numeric values throughout a DataFrame</a></span></li><li><span><a href=\"#Change-all-NaNs-to-None-(useful-before-loading-to-a-db)\" data-toc-modified-id=\"Change-all-NaNs-to-None-(useful-before-loading-to-a-db)-3.2.27.21\"><span class=\"toc-item-num\">3.2.27.21&nbsp;&nbsp;</span>Change all NaNs to None (useful before loading to a db)</a></span></li><li><span><a href=\"#Split-delimited-values-in-a-DataFrame-column-into-two-new-columns\" data-toc-modified-id=\"Split-delimited-values-in-a-DataFrame-column-into-two-new-columns-3.2.27.22\"><span class=\"toc-item-num\">3.2.27.22&nbsp;&nbsp;</span>Split delimited values in a DataFrame column into two new columns</a></span></li><li><span><a href=\"#Collapse-hierarchical-column-indexes\" data-toc-modified-id=\"Collapse-hierarchical-column-indexes-3.2.27.23\"><span class=\"toc-item-num\">3.2.27.23&nbsp;&nbsp;</span>Collapse hierarchical column indexes</a></span></li><li><span><a href=\"#change-a-Series-to-the-‘category’-data-type-(reduces-memory-usage-and-increases-performance)\" data-toc-modified-id=\"change-a-Series-to-the-‘category’-data-type-(reduces-memory-usage-and-increases-performance)-3.2.27.24\"><span class=\"toc-item-num\">3.2.27.24&nbsp;&nbsp;</span>change a Series to the ‘category’ data type (reduces memory usage and increases performance)</a></span></li><li><span><a href=\"#temporarily-define-a-new-column-as-a-function-of-existing-columns\" data-toc-modified-id=\"temporarily-define-a-new-column-as-a-function-of-existing-columns-3.2.27.25\"><span class=\"toc-item-num\">3.2.27.25&nbsp;&nbsp;</span>temporarily define a new column as a function of existing columns</a></span></li></ul></li></ul></li></ul></li></ul></div>","metadata":{}},{"cell_type":"markdown","source":"# Data Structures","metadata":{}},{"cell_type":"markdown","source":"There are two things to keep in mind for each of the data types you are using:\n\n1. Are they **mutable**?\n    - Mutability is about whether or not we can change an object once it has been created. A list can be changed so it is mutable. However, strings cannot be changed without creating a completely new object, so they are immutable.\n2. Are they **ordered**?\n    - Order is about whether the order of the elements in an object matters, and whether this position of an element can be used to access the element. Both strings and lists are ordered. We can use the order to access parts of a list and string.\n- For each of the upcoming data structures you see, it is useful to understand how you index, are they mutable, and are they ordered.\n- Additionally, you will see how these each have different methods, so why you would use one data structure vs. another is largely dependent on these properties, and what you can easily do with it!","metadata":{}},{"cell_type":"markdown","source":"## Lists[]\n**mutable, ordered sequence of elements.**\n- Mix of data types.\n- Are ordered - can lookup elements by index.\n- Are mutable - can be changed.","metadata":{}},{"cell_type":"markdown","source":"### List Comprehensions - (do.. for)","metadata":{}},{"cell_type":"code","source":"names = ['dumbledore', 'beeblebrox', 'skywalker', 'hermione', 'leia']\ncapitalized_names = []\nfor name in names:\n    capitalized_names.append(name.title())\n\n# equals (do.. for)\ncapitalized_names = [name.title() for name in names]\ncapitalized_names","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### adding conditionals (do.. for.. if)","metadata":{}},{"cell_type":"code","source":"squares = [x**2 for x in range(9) if x % 2 == 0]\n# to add else statements, move the conditionals to the beginning\nsquares = [x**2 if x % 2 == 0 else x + 3 for x in range(9)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### examples","metadata":{}},{"cell_type":"code","source":"# example\nnames = [\"Rick S\", \"Morty Smith\", \"Summer Smith\", \"Jerry Smith\", \"Beth Smith\"]\nfirst_names = [name.split(' ')[0] for name in names]\nprint(first_names)\n# ['Rick', 'Morty', 'Summer', 'Jerry', 'Beth']\n\n# example\nmultiples_3 = [i*3 for i in range(1,21)]\nprint(multiples_3)\n# [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60]\n\n# example\nscores = {\n             \"Rick\": 70,\n             \"Morty Smith\": 35,\n             \"Summer Smith\": 82,\n             \"Jerry Smith\": 23,\n             \"Beth Smith\": 98\n          }\npassed = [name for name, score in scores.items() if score>=65]\nprint(passed)\n# ['Rick', 'Summer Smith', 'Beth Smith']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lambda Functions","metadata":{}},{"cell_type":"code","source":"# Lambda Functions - lambda (arg1, arg2): do_a_thing_and_return_it\nmultiply = lambda x, y: x * y\n\n# Equivalent of:\ndef multiply(x, y):\n    return x * y\n\n# Can call both of the above like:\nmultiply(4, 7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### map() - apply lambda function to a list","metadata":{}},{"cell_type":"code","source":"# example of using map() to apply lambda function to a list\nnumbers = [\n              [34, 63, 88, 71, 29],\n              [90, 78, 51, 27, 45],\n              [63, 37, 85, 46, 22],\n              [51, 22, 34, 11, 18]\n           ]\nmean = lambda num_list: sum(num_list)/len(num_list)\naverages = list(map(mean, numbers))\n# or\naverages = list(map(lambda num_list: sum(num_list)/len(num_list), numbers))\nprint(averages)\n# [57.0, 58.2, 50.6, 27.2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### filter() - apply lambda function to a list","metadata":{}},{"cell_type":"code","source":"# example of using filter() to apply lambda function to a list\ncities = [\"New York City\", \"Los Angeles\", \"Chicago\", \"Mountain View\", \"Denver\", \"Boston\"]\nis_short = lambda name: len(name) < 10\nshort_cities = list(filter(is_short, cities))\n# or\nshort_cities = list(filter(lambda name: len(name) < 10, cities))\nprint(short_cities)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generators","metadata":{}},{"cell_type":"code","source":"# Generators\ndef my_range(x):\n    i = 0\n    while i < x:\n        yield i\n        i += 1\n# since this returns an iterator, we can convert it to a list\n# or iterate through it in a loop to view its contents\nfor x in my_range(5):\n    print(x)\n'''\n0\n1\n2\n3\n4\n'''\n\n# You can create a generator in the same way you'd normally write a list comprehension, except with\n# parentheses instead of square brackets.\n# this list comprehension produces a list of squares\nsq_list = [x**2 for x in range(10)]\n# this generator produces an iterator of squares\nsq_iterator = (x**2 for x in range(10))\n\n# example\n# generator function that works like the built-in function enumerate\nlessons = [\"Why Python Programming\", \"Data Types and Operators\", \"Control Flow\", \"Functions\", \"Scripting\"]\ndef my_enumerate(iterable, start=0):\n    i = start\n    for element in iterable:\n        yield i, element\n        i = i + 1\nfor i, lesson in my_enumerate(lessons, 1):\n    print(\"Lesson {}: {}\".format(i, lesson))\n'''\nLesson 1: Why Python Programming\nLesson 2: Data Types and Operators\nLesson 3: Control Flow\nLesson 4: Functions\nLesson 5: Scripting\n'''\n\n# example\n# If you have an iterable that is too large to fit in memory in full\n# (e.g., when dealing with large files), being able to take and use\n# chunks of it at a time can be very valuable.\n# Implementing a generator function, chunker, that takes in an\n# iterable and yields a chunk of a specified size at a time.\ndef chunker(iterable, size):\n    for i in range(0, len(iterable), size):\n        yield iterable[i:i + size]\nfor chunk in chunker(range(25), 4):\n    print(list(chunk))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create list","metadata":{}},{"cell_type":"code","source":"list_of_random_things = [1, 3.4, 'a string', True]","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### access list elements","metadata":{}},{"cell_type":"code","source":"list_of_random_things[0];\nlist_of_random_things[-1]; #last element\nlist_of_random_things[len(list_of_random_things) - 1]; #last element","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### slicing [,)","metadata":{}},{"cell_type":"code","source":"list_of_random_things[1:3] # returns [3.4, 'a string']\nlist_of_random_things[:2] # returns [1, 3.4]\nlist_of_random_things[1:] # returns all of the elements to the end of the list [3.4, 'a string', True]","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### in, not in","metadata":{}},{"cell_type":"code","source":"# in, not in\n'this' in 'this is a string' # True\n'in' in 'this is a string' # True\n'isa' in 'this is a string' # False\n5 not in [1, 2, 3, 4, 6] # True\n5 in [1, 2, 3, 4, 6] # False","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mutable and ordered","metadata":{}},{"cell_type":"code","source":"# Mutable and ordered\nmy_lst = [1, 2, 3, 4, 5]\nmy_lst[0] = 0\nprint(my_lst)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### length of list","metadata":{}},{"cell_type":"code","source":"# length of list\nlen(list_of_random_things)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### smallest and greatest element in list","metadata":{}},{"cell_type":"code","source":"# returns the smallest element of the list\nmin(list_of_random_things)\n\n# returns the greatest element of the list. This works because the the max function is defined in terms of the greater than comparison operator. The max function is undefined for lists that contain elements from different, incomparable types.\nmax(list_of_random_things)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### sort list","metadata":{}},{"cell_type":"code","source":"# returns a copy of a list in order from smallest to largest,\n# leaving the list unchanged.\nsorted(list_of_random_things)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### join()","metadata":{}},{"cell_type":"code","source":"# join() returns a string consisting of the list elements joined by a separator string.\n# Takes only a list of strings as an argument\nname = \"-\".join([\"Grace\", \"Kelly\"])\nprint(name) # Grace-Kelly","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating a new list","metadata":{}},{"cell_type":"code","source":"cities = ['new york city', 'mountain view', 'chicago', 'los angeles']\ncapitalized_cities = []\nfor city in cities:\n    capitalized_cities.append(city.title())","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding an element to the end of a list - append()","metadata":{}},{"cell_type":"code","source":"letters = ['a', 'b', 'c', 'd']\nletters.append('z')\nprint(letters) # ['a', 'b', 'c', 'd', 'z']\n# Note: letters[i] = 'z'; wouldn't work, use append()","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modifying a new list","metadata":{}},{"cell_type":"code","source":"cities = ['new york city', 'mountain view', 'chicago', 'los angeles']\nfor index in range(len(cities)):\n    cities[index] = cities[index].title()","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print a formatted string from parameters in list","metadata":{}},{"cell_type":"code","source":"items = ['first string', 'second string']\nhtml_str = \"<ul>\\n\"\nfor item in items:\n    html_str += \"<li>{}</li>\\n\".format(item)\nhtml_str += \"</ul>\"\nprint(html_str)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert an iterable (tuple, string, set, dictionary) to a list - list()","metadata":{}},{"cell_type":"code","source":"# vowel string\nvowelString = 'aeiou'\nprint(list(vowelString))\n\n# vowel tuple\nvowelTuple = ('a', 'e', 'i', 'o', 'u')\nprint(list(vowelTuple))\n\n# vowel list\nvowelList = ['a', 'e', 'i', 'o', 'u']\nprint(list(vowelList))\n\n# All Print: ['a', 'e', 'i', 'o', 'u']","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tuples()\n**immutable ordered sequences of elements.**\n- They are often used to store related pieces of information. The parentheses are optional when defining tuples.\n- Are ordered - can lookup elements by index.\n- Are immutable - can not be changed. You can't add and remove items from tuples, or sort them in place.","metadata":{}},{"cell_type":"markdown","source":"### create tuple","metadata":{}},{"cell_type":"code","source":"location = (13.4125, 103.866667)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### access tuple","metadata":{}},{"cell_type":"code","source":"print(\"Latitude:\", location[0])\nprint(\"Longitude:\", location[1])","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### tuple packing","metadata":{}},{"cell_type":"code","source":"# can also be used to assign multiple variables in a compact way\ndimensions = 52, 40, 100","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### tuple unpacking","metadata":{}},{"cell_type":"code","source":"# tuple unpacking\nlength, width, height = dimensions\nprint(\"The dimensions are {} x {} x {}\".format(length, width, height))","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sets{}\n**mutable, unordered collections of unique elements.**\n- Are unordered - can not lookup elements by index.\n- Are mutable - can be changed.\n- Sets support the **in** operator the same as lists do.\n- One application of a set is to quickly remove duplicates from a list.\n- You cannot have the same item twice and you cannot sort sets. For these two properties a list would be more appropriate.\n- You can add elements to sets using the **add()** method, and remove elements using the **pop()** method, similar to lists. Although, when you pop an element from a set, a random element is removed. Remember that sets, unlike lists, are unordered so there is no \"last element\".\n- Other operations you can perform with sets include those of mathematical sets. Methods like union, intersection, and difference are easy to perform with sets, and are much faster than such operators with other containers.","metadata":{}},{"cell_type":"markdown","source":"### create sets","metadata":{}},{"cell_type":"code","source":"numbers = [1, 2, 6, 3, 1, 1, 6]\nunique_nums = set(numbers)\nprint(unique_nums) # {1, 2, 3, 6}","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fruit = {\"apple\", \"banana\", \"orange\", \"grapefruit\"}","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### check for element","metadata":{}},{"cell_type":"code","source":"print(\"watermelon\" in fruit)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### add an element","metadata":{}},{"cell_type":"code","source":"fruit.add(\"watermelon\")\nprint(fruit)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### remove a random element","metadata":{}},{"cell_type":"code","source":"print(fruit.pop())\nprint(fruit)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dicts{}\n**mutable data type that stores mappings of unique keys to values.**\n- Are ordered - can lookup elements by key.\n- Are mutable - can be changed.\n- Dictionaries can have *keys of any immutable type*, like integers or tuples, not just strings. It's not even necessary for every key to have the same type!\n- We can look up values or insert new values in the dictionary using square brackets that enclose the key.","metadata":{}},{"cell_type":"markdown","source":"### create dict","metadata":{}},{"cell_type":"code","source":"elements = {\"hydrogen\": 1, \"helium\": 2, \"carbon\": 6}","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### accessing an element's value","metadata":{}},{"cell_type":"code","source":"print(elements[\"helium\"])","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### adding elements","metadata":{}},{"cell_type":"code","source":"elements[\"lithium\"] = 3 ","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Iterating through a dictionary","metadata":{}},{"cell_type":"code","source":"# Just keys\nfor key in cast:\n    print(key)\n# Keys and values\nfor key, value in cast.items():\n    print(\"Actor: {}    Role: {}\".format(key, value))","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### check whether a value is in a dictionary","metadata":{}},{"cell_type":"code","source":"# check whether a value is in a dictionary, the same way we check whether a value is in a list or set with the in keyword.\nprint(\"carbon\" in elements) # True","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### get() looks up values in a dictionary","metadata":{}},{"cell_type":"code","source":"# get() looks up values in a dictionary, but unlike square brackets, get returns None (or a default value of your choice) if the key isn't found.\n# If you expect lookups to sometimes fail, get might be a better tool than normal square bracket lookups.\nprint(elements.get(\"dilithium\")) # None\nprint(elements.get('kryptonite', 'There\\'s no such element!'))\n# \"There's no such element!\"","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Identity Operators","metadata":{}},{"cell_type":"code","source":"n = elements.get(\"dilithium\")\nprint(n is None) # True\nprint(n is not None) # False","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Equality (==) and identity (is)","metadata":{}},{"cell_type":"code","source":"a = [1, 2, 3]\nb = a\nc = [1, 2, 3]\nprint(a == b) # True\nprint(a is b) # True\nprint(a == c) # True\nprint(a is c) # False\n# List a and list b are equal and identical.\n# List c is equal to a (and b for that matter) since they have the same contents. But a and c (and b for that matter, again) point to two different objects, i.e., they aren't identical objects.\n# That is the difference between checking for equality vs. identity.","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compound Data Structures","metadata":{}},{"cell_type":"code","source":"elements = {\"hydrogen\": {\"number\": 1,\n                         \"weight\": 1.00794,\n                         \"symbol\": \"H\"},\n              \"helium\": {\"number\": 2,\n                         \"weight\": 4.002602,\n                         \"symbol\": \"He\"}}\nhelium = elements[\"helium\"]  # get the helium dictionary\nhydrogen_weight = elements[\"hydrogen\"][\"weight\"]  # get hydrogen's weight\noxygen = {\"number\":8,\"weight\":15.999,\"symbol\":\"O\"}  # create a new oxygen dictionary \nelements[\"oxygen\"] = oxygen  # assign 'oxygen' as a key to the elements dictionary\nprint('elements = ', elements)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dict frequency counter","metadata":{}},{"cell_type":"code","source":"words =  ['great', 'expectations','the', 'adventures', 'of', 'sherlock','holmes','the','great','gasby','hamlet','adventures','of','huckleberry','fin'];\nword_counter = {}\nfor word in words:\n    word_counter[word] = word_counter.get(word,0)+1;\nprint(word_counter);\n# Prints {'fin': 1, 'huckleberry': 1, 'hamlet': 1, 'holmes': 1, 'adventures': 2, 'sherlock': 1, 'expectations': 1, 'great': 2, 'the': 2, 'of': 2, 'gasby': 1}","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numpy","metadata":{}},{"cell_type":"markdown","source":"[Jupyter Notebook Viewer](https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/tools_numpy.ipynb)\n\n[Python Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/#numpy)\n\n- NumPy provides Python with an extensive math library capable of performing numerical computations effectively and efficiently.\n    - Even though Python lists are great on their own, NumPy has a number of key features that give it great advantages over Python lists. One such feature is speed. When performing operations on large arrays NumPy can often perform several orders of magnitude faster than Python lists. This speed comes from the nature of NumPy arrays being memory-efficient and from optimized algorithms used by NumPy for doing arithmetic, statistical, and linear algebra operations.\n    - Another great feature of NumPy is that it has multidimensional array data structures that can represent vectors and matrices. Another great advantage of NumPy over Python lists is that NumPy has a large number of optimized built-in mathematical functions. These functions allow you to do a variety of complex mathematical computations very fast and with very little code (avoiding the use of complicated loops) making your programs more readable and easier to understand.\n- At the core of NumPy is the **ndarray**, where nd stands for n-dimensional.\n    - An ndarray is a multidimensional array of elements **all of the same type**.\n    - Unlike Python lists, all the elements of an ndarray must be of the same type. If you provide the np.array() function with a Python list that has both integers and strings, NumPy will interpret all elements as strings.\n    - When we create an ndarray with both floats and integers, NumPy assigns its elements a float64 dtype. This is called **upcasting**. Since all the elements of an ndarray must be of the same type, in this case NumPy upcasts the integers in z to floats in order to avoid losing precision in numerical computations.\n- We refer to 1D arrays as rank 1 arrays. In general N-Dimensional arrays have rank N. Therefore, we refer to a 2D array as a rank 2 array.","metadata":{}},{"cell_type":"markdown","source":"Read this about how data is arranged in numpy and using reshape: https://stackoverflow.com/questions/22053050/difference-between-numpy-array-shape-r-1-and-r","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create ndarray","metadata":{}},{"cell_type":"code","source":"# Create a 1D ndarray that contains only integers\nx = np.array([1, 2, 3, 4, 5])\nprint('x = ', x) # x = [1 2 3 4 5]\nprint('x has dimensions:', x.shape) # x has dimensions: (5,)\nprint('The elements in x are of type:', x.dtype) # The elements in x are of type: int64\n\n# Create a rank 2 ndarray that only contains integers\nY = np.array([[1,2,3],[4,5,6],[7,8,9], [10,11,12]])\nprint('Y has dimensions:', Y.shape) # Y has dimensions: (4, 3)\nprint('Y has a total of', Y.size, 'elements') # Y has a total of 12 elements\nprint('Y is an object of type:', type(Y)) # Y is an object of type: class 'numpy.ndarray'\nprint('The elements in Y are of type:', Y.dtype) # The elements in Y are of type: int64","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create ndarray with dtype","metadata":{}},{"cell_type":"code","source":"# Specify the dtype when creating the ndarray\nx = np.array([1.5, 2.2, 3.7, 4.0, 5.9], dtype = np.int64)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save and load","metadata":{}},{"cell_type":"code","source":"# Save the array into a file\nnp.save('my_array', x)\n\n# Load the saved array from current directory\ny = np.load('my_array.npy')","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Zeros","metadata":{}},{"cell_type":"code","source":"# Create ndarray using built-in functions\n# 3 x 4 ndarray full of zeros\n# np.zeros(shape)\nX = np.zeros((3,4))","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ones","metadata":{}},{"cell_type":"code","source":"# a 3 x 2 ndarray full of ones\n# np.ones(shape)\nX = np.ones((3,2))","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Full","metadata":{}},{"cell_type":"code","source":"# 2 x 3 ndarray full of fives\n# np.full(shape, constant value)\nX = np.full((2,3), 5)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Identity Matrix","metadata":{}},{"cell_type":"code","source":"# Identity Matrix\n# Since all Identity Matrices are square, the np.eye() function only takes a single integer as an argument\n# 5 x 5 Identity matrix\nX = np.eye(5)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Diagonal Matrix","metadata":{}},{"cell_type":"code","source":"# Diagonal Matrix\n# 4 x 4 diagonal matrix that contains the numbers 10,20,30, and 50 on its main diagonal\nX = np.diag([10,20,30,50])","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Arange","metadata":{}},{"cell_type":"code","source":"# Arange\n# rank 1 ndarray that has sequential integers from 0 to 9\n# x = [0 1 2 3 4 5 6 7 8 9]\nx = np.arange(10)\n\n# rank 1 ndarray that has sequential integers from 4 to 9\n# [start, stop)\n# x = [4 5 6 7 8 9]\nx = np.arange(4,10)\n\n# rank 1 ndarray that has evenly spaced integers from 1 to 13 in steps of 3.\n# np.arange(start,stop,step)\n# x = [ 1 4 7 10 13]\nx = np.arange(1,14,3)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linspace","metadata":{}},{"cell_type":"code","source":"# Linspace\n# Even though the np.arange() function allows for non-integer steps,\n# such as 0.3, the output is usually inconsistent, due to the finite\n# floating point precision. For this reason, in the cases where\n# non-integer steps are required, it is usually better to use linspace()\n# becayse np.linspace() uses the number of elements we want in a\n# particular interval, instead of the step between values.\n# linspace returns N evenly spaced numbers over the closed interval [start, stop]\n# np.linspace(start, stop, N)\n# x = [ 0. 2.77777778 5.55555556 8.33333333 11.11111111 13.88888889 16.66666667 19.44444444 22.22222222 25. ]\nx = np.linspace(0,25,10)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reshape","metadata":{}},{"cell_type":"code","source":"# Reshape\n# np.reshape(ndarray, new_shape)\n# converts the given ndarray into the specified new_shape\nx = np.arange(20)\nx = np.reshape(x, (4,5))\n# or\nx = np.arange(20).reshape(4, 5) # does the same thing as above\n# and the same thing with with linshape\ny = np.linspace(0,50,10, endpoint=False).reshape(5,2)\n# One great feature about NumPy, is that some functions can also be\n# applied as methods. This allows us to apply different functions in\n# sequence in just one line of code","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Slicing","metadata":{}},{"cell_type":"code","source":"# Slicing\n# ndarray[start:end]\n# ndarray[start:]\n# ndarray[:end]\n# ndarray[<start>:<stop>:<step>]\n\n# In methods one and three, the end index is excluded [,)\nX = np.arange(20).reshape(4, 5)\n\n# select all the elements that are in the 2nd through 4th rows and in the 3rd to 5th columns\nZ = X[1:4,2:5]\n# or\nZ = X[1:,2:5]\n\n# elements = a_list[<start>:<stop>:<step>]\n# select all the elements in the 3rd row\nv = X[2,:] # v = [10 11 12 13 14]\n# select all the elements in the 3rd column\nq = X[:,2] # q = [ 2 7 12 17]\n# select all the elements in the 3rd column but return a rank 2 ndarray\nR = X[:,2:3]\n'''\n[[ 2]\n [ 7]\n [12]\n [17]]\n'''\n# Note: Slicing creates a view, not a copy\n# when we make assignments, such as: Z = X[1:4,2:5]\n# the slice of the original array X is not copied in the variable Z.\n# Rather, X and Z are now just two different names for the same ndarray.\n# We say that slicing only creates a view of the original array.\n# This means if we make changes to Z, X changes as well.","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random","metadata":{}},{"cell_type":"code","source":"# Random\n# 3 x 3 ndarray with random floats in the half-open interval [0.0, 1.0).\n# np.random.random(shape)\nX = np.random.random((3,3))\n# np.random.randint(start, stop, size = shape)\n# [start, stop)\nX = np.random.randint(4,15,size=(3,2))\n\n# create ndarrays with random numbers that satisfy certain statistical properties\n# 1000 x 1000 ndarray of random floats drawn from normal (Gaussian)\n# distribution with a mean of zero and a standard deviation of 0.1.\n# np.random.normal(mean, standard deviation, size=shape)\nX = np.random.normal(0, 0.1, size=(1000,1000))","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mutability","metadata":{}},{"cell_type":"code","source":"# Mutability\n# Change ndarray\nx[3] = 20\nX[0,0] = 20","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Delete","metadata":{}},{"cell_type":"code","source":"# Delete\n# np.delete(ndarray, elements, axis)\nx = np.array([1, 2, 3, 4, 5])\n# delete the first and fifth element of x\nx = np.delete(x, [0,4])\n\nY = np.array([[1,2,3],[4,5,6],[7,8,9]])\n# delete the first row of Y\nw = np.delete(Y, 0, axis=0)\n# delete the first and last column of Y\nv = np.delete(Y, [0,2], axis=1)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Append","metadata":{}},{"cell_type":"code","source":"# Append\n# np.append(ndarray, elements, axis)\n# append the integer 6 to x\nx = np.append(x, 6)\n# append the integer 7 and 8 to x\nx = np.append(x, [7,8])\n# append a new row containing 7,8,9 to y\nv = np.append(Y, [[10,11,12]], axis=0)\n# append a new column containing 9 and 10 to y\nq = np.append(Y,[[13],[14],[15]], axis=1)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insert","metadata":{}},{"cell_type":"code","source":"# Insert\n# np.insert(ndarray, index, elements, axis)\n# inserts the given list of elements to ndarray right before\n# the given index along the specified axis\nx = np.array([1, 2, 5, 6, 7])\nY = np.array([[1,2,3],[7,8,9]])\n# insert the integer 3 and 4 between 2 and 5 in x. \nx = np.insert(x,2,[3,4])\n# insert a row between the first and last row of Y\nw = np.insert(Y,1,[4,5,6],axis=0)\n# insert a column full of 5s between the first and second column of Y\nv = np.insert(Y,1,5, axis=1)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacking","metadata":{}},{"cell_type":"code","source":"# Stacking\n# NumPy also allows us to stack ndarrays on top of each other,\n# or to stack them side by side. The stacking is done using either\n# the np.vstack() function for vertical stacking, or the np.hstack()\n# function for horizontal stacking. It is important to note that in\n# order to stack ndarrays, the shape of the ndarrays must match.\nx = np.array([1,2])\nY = np.array([[3,4],[5,6]])\nz = np.vstack((x,Y)) # [[1,2], [3,4], [5,6]]\nw = np.hstack((Y,x.reshape(2,1))) # [[3,4,1], [5,6,2]]","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Copy","metadata":{}},{"cell_type":"code","source":"# Copy\n# if we want to create a new ndarray that contains a copy of the\n# values in the slice we need to use the np.copy()\n# create a copy of the slice using the np.copy() function\nZ = np.copy(X[1:4,2:5])\n#  create a copy of the slice using the copy as a method\nW = X[1:4,2:5].copy()","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract elements along the diagonal","metadata":{}},{"cell_type":"code","source":"# Extract elements along the diagonal\nd0 = np.diag(X)\n# As default is k=0, which refers to the main diagonal.\n# Values of k > 0 are used to select elements in diagonals above\n# the main diagonal, and values of k < 0 are used to select elements\n# in diagonals below the main diagonal.\nd1 = np.diag(X, k=1)\nd2 = np.diag(X, k=-1)","metadata":{"_kg_hide-output":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Find Unique Elements","metadata":{}},{"cell_type":"code","source":"# Find Unique Elements in ndarray\nu = np.unique(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boolean Indexing","metadata":{}},{"cell_type":"code","source":"# Boolean Indexing\nX = np.arange(25).reshape(5, 5)\nprint('The elements in X that are greater than 10:', X[X > 10])\nprint('The elements in X that less than or equal to 7:', X[X <= 7])\nprint('The elements in X that are between 10 and 17:', X[(X > 10) & (X < 17)])\n\n# use Boolean indexing to assign the elements that\n# are between 10 and 17 the value of -1\nX[(X > 10) & (X < 17)] = -1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Operations","metadata":{}},{"cell_type":"code","source":"# Set Operations\nx = np.array([1,2,3,4,5])\ny = np.array([6,7,2,8,4])\nprint('The elements that are both in x and y:', np.intersect1d(x,y))\nprint('The elements that are in x that are not in y:', np.setdiff1d(x,y))\nprint('All the elements of x and y:',np.union1d(x,y))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sorting","metadata":{}},{"cell_type":"code","source":"# Sorting\n# When used as a function, it doesn't change the original ndarray\ns = np.sort(x)\n# When used as a method, the original array will be sorted\nx.sort()\n\n# sort x but only keep the unique elements in x\ns = np.sort(np.unique(x))\n\n# sort the columns of X\ns = np.sort(X, axis = 0)\n\n# sort the rows of X\ns = np.sort(X, axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Math Functions","metadata":{}},{"cell_type":"code","source":"# NumPy allows element-wise operations on ndarrays as well as\n# matrix operations. In order to do element-wise operations,\n# NumPy sometimes uses something called Broadcasting.\n# Broadcasting is the term used to describe how NumPy handles\n# element-wise arithmetic operations with ndarrays of different shapes.\n# For example, broadcasting is used implicitly when doing arithmetic\n# operations between scalars and ndarrays.\nx = np.array([1,2,3,4])\ny = np.array([5.5,6.5,7.5,8.5])\nnp.add(x,y)\nnp.subtract(x,y)\nnp.multiply(x,y)\nnp.divide(x,y)\n\n# in order to do these operations the shapes of the ndarrays\n# being operated on, must have the same shape or be broadcastable\nX = np.array([1,2,3,4]).reshape(2,2)\nY = np.array([5.5,6.5,7.5,8.5]).reshape(2,2)\nnp.add(X,Y)\nnp.subtract(X,Y)\nnp.multiply(X,Y)\nnp.divide(X,Y)\n\n# apply mathematical functions to all elements of an ndarray at once\nnp.exp(x)\nnp.sqrt(x)\nnp.power(x,2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Statistical Functions","metadata":{}},{"cell_type":"code","source":"# Statistical Functions\nprint('Average of all elements in X:', X.mean())\nprint('Average of all elements in the columns of X:', X.mean(axis=0))\nprint('Average of all elements in the rows of X:', X.mean(axis=1))\nprint()\nprint('Sum of all elements in X:', X.sum())\nprint('Standard Deviation of all elements in X:', X.std())\nprint('Median of all elements in X:', np.median(X))\nprint('Maximum value of all elements in X:', X.max())\nprint('Minimum value of all elements in X:', X.min())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Broadcasting","metadata":{}},{"cell_type":"code","source":"# Broadcasting\n# NumPy is working behind the scenes to broadcast 3 along the ndarray\n# so that they have the same shape. This allows us to add 3 to each\n# element of X with just one line of code.\nprint(4*X)\nprint(4+X)\nprint(4-X)\nprint(4/X)\n# NumPy is able to add 1 x 3 and 3 x 1 ndarrays to 3 x 3 ndarrays\n# by broadcasting the smaller ndarrays along the big ndarray so that\n# they have compatible shapes. In general, NumPy can do this provided\n# that the smaller ndarray can be expanded to the shape of the larger\n# ndarray in such a way that the resulting broadcast is unambiguous.\nx = np.array([1,2,3])\nY = np.array([[1,2,3],[4,5,6],[7,8,9]])\nZ = np.array([1,2,3]).reshape(3,1)\nprint(x + Y)\nprint(Z + Y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas","metadata":{}},{"cell_type":"markdown","source":"[Jupyter Notebook Viewer](https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/tools_pandas.ipynb)\n\n- Pandas is a package for data manipulation and analysis in Python. The name Pandas is derived from the econometrics term Panel Data. Pandas incorporates two additional data structures into Python, namely Pandas Series and Pandas DataFrame. These data structures allow us to work with labeled and relational data in an easy and intuitive manner.\n- Pandas Series and DataFrames are designed for fast data analysis and manipulation, as well as being flexible and easy to use. Below are just a few features that makes Pandas an excellent package for data analysis:\n    - Allows the use of labels for rows and columns\n    - Can calculate rolling statistics on time series data\n    - Easy handling of NaN values\n    - Is able to load data of different formats into DataFrames\n    - Can join and merge different datasets together\n    - It integrates with NumPy and Matplotlib\n- Documentation: [https://pandas.pydata.org/pandas-docs/stable/](https://pandas.pydata.org/pandas-docs/stable/)","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Series\n1D array-like object that can hold many data types. One of the main differences between Pandas Series and NumPy ndarrays is that you can assign an index label to each element in the Pandas Series. Another big difference is that Pandas Series can hold data of different data types.\n\npd.Series(data, index)","metadata":{}},{"cell_type":"markdown","source":"### Create Series","metadata":{}},{"cell_type":"code","source":"groceries = pd.Series(data = [30, 6, 'Yes', 'No'], index = ['eggs', 'apples', 'milk', 'bread'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### shape, size, values, index, ndim","metadata":{}},{"cell_type":"code","source":"print('Groceries has shape:', groceries.shape)\nprint('Groceries has dimension:', groceries.ndim)\nprint('Groceries has a total of', groceries.size, 'elements')\nprint('The data in Groceries is:', groceries.values)\nprint('The index of Groceries is:', groceries.index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### check whether an index label exists in Series","metadata":{}},{"cell_type":"code","source":"# check whether an index label exists in Series\nx = 'bananas' in groceries","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accessing Elements","metadata":{}},{"cell_type":"code","source":"# Accessing Elements\n# using index labels:\n# single index label\nprint('How many eggs do we need to buy:', groceries['eggs'])\n# access multiple index labels\nprint('Do we need milk and bread:\\n', groceries[['milk', 'bread']]) \n# use loc to access multiple index labels\nprint('How many eggs and apples do we need to buy:\\n', groceries.loc[['eggs', 'apples']]) \n\n# access elements in Groceries using numerical indices:\n# use multiple numerical indices\nprint('How many eggs and apples do we need to buy:\\n',  groceries[[0, 1]]) \n# use a negative numerical index\nprint('Do we need bread:\\n', groceries[[-1]]) \n# use a single numerical index\nprint('How many eggs do we need to buy:', groceries[0]) \n# use iloc (stands for integer location) to access multiple numerical indices\nprint('Do we need milk and bread:\\n', groceries.iloc[[2, 3]])\n# Since we can access elements in various ways, in order to remove\n# any ambiguity to whether we are referring to an index label\n# or numerical index, Pandas Series have two attributes,\n# .loc and .iloc to explicitly state what we mean. The attribute\n# .loc stands for location and it is used to explicitly state that\n# we are using a labeled index. Similarly, the attribute .iloc stands\n# for integer location and it is used to explicitly state that we are\n# using a numerical index.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# access using Boolean Indexes\ntime_light[time_light<40]","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Change Elements","metadata":{}},{"cell_type":"code","source":"# Change Elements\ngroceries['eggs'] = 2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Delete Elements","metadata":{}},{"cell_type":"code","source":"# Delete Elements\n# doesn't change the original Series being modified\ngroceries.drop('apples')\n# delete items from Series in place by setting keyword inplace to True\ngroceries.drop('apples', inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Arithmetic Operations","metadata":{}},{"cell_type":"code","source":"# Arithmetic Operations\n# we can perform element-wise arithmetic operations on Pandas Series\nfruits = pd.Series(data = [10, 6, 3,], index = ['apples', 'oranges', 'bananas'])\nfruits + 2 # Adds 2 to all elements in the series\nfruits - 2\nfruits * 2\nfruits / 2\n# apply mathematical functions from NumPy to all elements of a Series\nnp.exp(fruits)\nnp.sqrt(fruits)\nnp.power(fruits,2)\n# only apply arithmetic operations on selected items in Series\nfruits['bananas'] + 2\nfruits.iloc[0] - 2\nfruits[['apples', 'oranges']] * 2\n# you can apply arithmetic operations on a Series of mixed data\n# type provided that the arithmetic operation is defined for all\n# data types in the Series, otherwise you will get an error","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataframe\nPandas DataFrames are two-dimensional data structures with labeled rows and columns, that can hold many data types.","metadata":{}},{"cell_type":"markdown","source":"### Axes","metadata":{}},{"cell_type":"code","source":"# understanding axes\ndf.sum()       \n# sums “down” the 0 axis (rows)\ndf.sum(axis=0) \n# equivalent (since axis=0 is the default)\ndf.sum(axis=1) \n# sums “across” the 1 axis (columns)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading Data into DF","metadata":{}},{"cell_type":"code","source":"# Loading Data into DF\ndf = pd.read_csv('marauders_map.csv')\n\n# limit which rows are read when reading in a file\npd.read_csv(‘df.csv’, nrows=10)        \n# only read first 10 rows\n\npd.read_csv(‘df.csv’, skiprows=[1, 2]) \n# skip the first two rows of data\n\n# randomly sample a DataFrame\ntrain = df.sample(frac=0.75, random_column_y=1) \n# will contain 75% of the rows\n\ntest = df[~df.index.isin(train.index)] \n# will contain the other 25%\n\n# change the maximum number of rows and columns printed (‘None’ means unlimited)\npd.set_option(‘max_rows’, None) \n# default is 60 rows\n\npd.set_option(‘max_columns’, None) \n# default is 20 columns\nprint df\n\n# reset options to defaults\npd.reset_option(‘max_rows’)\npd.reset_option(‘max_columns’)\n\n# change the options temporarily (settings are restored when you exit the ‘with’ block)\nwith pd.option_context(‘max_rows’, None, ‘max_columns’, None):\n    print df","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Dataframe","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame manually from a dictionary of Pandas Series\n\n# create a dictionary of Pandas Series \nitems = {'Bob' : pd.Series(data = [245, 25, 55], index = ['bike', 'pants', 'watch']),\n         'Alice' : pd.Series(data = [40, 110, 500, 45], index = ['book', 'glasses', 'bike', 'pants'])}\n\n# print the type of items to see that it is a dictionary\nprint(type(items)) # class 'dict'\n\n# create a Pandas DataFrame by passing it a dictionary of Series\nshopping_carts = pd.DataFrame(items)\n\n# create a DataFrame that only has a subset of the data/columns\nbob_shopping_cart = pd.DataFrame(items, columns=['Bob'])\n\n# create a DataFrame that only has selected keys\nsel_shopping_cart = pd.DataFrame(items, index = ['pants', 'book'])\n\n# combine both of the above - selected keys for selected columns\nalice_sel_shopping_cart = pd.DataFrame(items, index = ['glasses', 'bike'], columns = ['Alice'])\n\n# create DataFrames from a dictionary of lists (arrays)\n# In this case, however, all the lists (arrays) in the dictionary must be of the same length\n\n# create a dictionary of lists (arrays)\ndata = {'Integers' : [1,2,3],\n        'Floats' : [4.5, 8.2, 9.6]}\n\n# create a DataFrame \ndf = pd.DataFrame(data)\n\n# create a DataFrame and provide the row index\ndf = pd.DataFrame(data, index = ['label 1', 'label 2', 'label 3'])\n\n# create DataFrames from a list of Python dictionaries\n# create a list of Python dictionaries\nitems2 = [{'bikes': 20, 'pants': 30, 'watches': 35}, \n          {'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5}]\n\n# create a DataFrame \nstore_items = pd.DataFrame(items2)\n\n# create a DataFrame and provide the row index\nstore_items = pd.DataFrame(items2, index = ['store 1', 'store 2'])\n\nprint('shopping_carts has shape:', shopping_carts.shape)\nprint('shopping_carts has dimension:', shopping_carts.ndim)\nprint('shopping_carts has a total of:', shopping_carts.size, 'elements')\nprint()\nprint('The data in shopping_carts is:\\n', shopping_carts.values)\nprint()\nprint('The row index in shopping_carts is:', shopping_carts.index)\nprint()\nprint('The column index in shopping_carts is:', shopping_carts.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create df from Series, dicts","metadata":{}},{"cell_type":"code","source":"# Create dictionary from a bunch of Series/data\nbooks = pd.Series(data = ['Great Expectations', 'Of Mice and Men', 'Romeo and Juliet', 'The Time Machine', 'Alice in Wonderland' ])\nauthors = pd.Series(data = ['Charles Dickens', 'John Steinbeck', 'William Shakespeare', ' H. G. Wells', 'Lewis Carroll' ])\nuser_1 = pd.Series(data = [3.2, np.nan ,2.5])\nuser_2 = pd.Series(data = [5., 1.3, 4.0, 3.8])\nuser_3 = pd.Series(data = [2.0, 2.3, np.nan, 4])\nuser_4 = pd.Series(data = [4, 3.5, 4, 5, 4.2])\n\n# Create a dictionary with the data given above\na_dict = {'Author':authors,'Book Title':books,'User 1':user_1, 'User 2':user_2, 'User 3':user_3, 'User 4':user_4}\n\n# Use the dictionary to create a Pandas DataFrame\nbook_ratings = pd.DataFrame(a_dict)\nbook_ratings[:5]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to numpy array (remove the column names, get just the values to convert it into a numpy array)\nbook_ratings_numpy = book_ratings.values\nbook_ratings_numpy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### create a DataFrame from a dictionary\npd.DataFrame({‘column_x’:[‘value_x1’, ‘value_x2’, ‘value_x3’], ‘column_y’:[‘value_y1’, ‘value_y2’, ‘value_y3’]})\n\n#### create a DataFrame from a list of lists\npd.DataFrame([[‘value_x1’, ‘value_y1’], [‘value_x2’, ‘value_y2’], [‘value_x3’, ‘value_y3’]], columns=[‘column_x’, ‘column_y’])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Access Elements","metadata":{}},{"cell_type":"code","source":"# Access Elements\nprint()\nprint('How many bikes are in each store:\\n', store_items[['bikes']])\nprint()\nprint('How many bikes and pants are in each store:\\n', store_items[['bikes', 'pants']])\nprint()\nprint('What items are in Store 1:\\n', store_items.loc[['store 1']])\nprint()\nprint('How many bikes are in Store 2:', store_items['bikes']['store 2'])\n# when accessing individual elements in a DataFrame, the labels\n# should always be provided with the column label first,\n# i.e. in the form dataframe[column][row]\n# store_items for reference:\n#          bikes\tglasses\tpants\twatches\n# store 1\t    20\t   NaN\t   30\t     35\n# store 2\t    15\t  50.0\t    5\t     10","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modify Elements","metadata":{}},{"cell_type":"code","source":"# Modify Elements\n# Add new column (adds it to the end of the df)\nstore_items['shirts'] = [15,2]\n\n# New column via artihmetic operations b/w columns\nstore_items['suits'] = store_items['pants'] + store_items['shirts']\n\n# Add new row\n\n# To add rows to our df, create a new df then append it to the original df\n# create a dictionary from a list of Python dictionaries\nnew_items = [{'bikes': 20, 'pants': 30, 'watches': 35, 'glasses': 4}]\n\n# create new DataFrame with the new_items and provide and index labeled store 3\nnew_store = pd.DataFrame(new_items, index = ['store 3'])\n\n# append store 3 to our store_items DataFrame\nstore_items = store_items.append(new_store)\n\n# insert a new column with label shoes right before the column with numerical index 4\nstore_items.insert(4, 'shoes', [8,5,0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Delete Element","metadata":{}},{"cell_type":"code","source":"# Delete Element\n\n# .pop() method only allows us to delete columns, while the .drop()\n# method can be used to delete both rows and columns by use of the axis keyword\n\n# remove the new watches column\nstore_items.pop('new watches')\n\n# remove the watches and shoes columns\nstore_items = store_items.drop(['watches', 'shoes'], axis = 1)\n\n# remove the store 2 and store 1 rows\nstore_items = store_items.drop(['store 2', 'store 1'], axis = 0)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rename the row and column labels","metadata":{}},{"cell_type":"code","source":"# Rename the row and column labels\n# change the column label\nstore_items = store_items.rename(columns = {'bikes': 'hats'})\n# change the row label\nstore_items = store_items.rename(index = {'store 3': 'last store'})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Change index","metadata":{}},{"cell_type":"code","source":"# change the index to be one of the columns in the DataFrame\nstore_items = store_items.set_index('pants')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dealing with NaN values (missing data)","metadata":{}},{"cell_type":"code","source":"# Dealing with NaN values (missing data)\n\n# create a list of Python dictionaries\nitems2 = [{'bikes': 20, 'pants': 30, 'watches': 35, 'shirts': 15, 'shoes':8, 'suits':45},\n{'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5, 'shirts': 2, 'shoes':5, 'suits':7},\n{'bikes': 20, 'pants': 30, 'watches': 35, 'glasses': 4, 'shoes':10}]\n\n# We create a DataFrame and provide the row index\nstore_items = pd.DataFrame(items2, index = ['store 1', 'store 2', 'store 3'])\n\n# check if we have any NaN values in our dataset\n# .any() performs an or operation. If any of the values along the\n# specified axis is True, this will return True.\ndf.isnull().any()\n'''\nDate   False\nOpen   True\nHigh   False\nLow    False\nClose  False\nVolume False\ndtype: bool\n'''\n\n# count the number of NaN values in DataFrame\nx =  store_items.isnull().sum().sum()\n# count the number of non-NaN values in DataFrame\nx = store_items.count()\n\n# remove rows or columns from our DataFrame that contain any NaN values\n\n# drop any rows with NaN values\nstore_items.dropna(axis = 0)\n\n# drop any columns with NaN values\nstore_items.dropna(axis = 1)\n\n# the original DataFrame is not modified by default\n# to remove missing values from original df, use inplace = True\nstore_items.dropna(axis = 0, inplace = True)\n\n# replace all NaN values with 0\nstore_items.fillna(0)\n\n# forward filling: replace NaN values with previous values in the df,\n# this is known as . When replacing NaN values with forward filling,\n# we can use previous values taken from columns or rows.\n# replace NaN values with the previous value in the column\nstore_items.fillna(method = 'ffill', axis = 0)\n\n# backward filling: replace the NaN values with the values that\n# go after them in the DataFrame\n# replace NaN values with the next value in the row\nstore_items.fillna(method = 'backfill', axis = 1)\n\n# replace NaN values by using linear interpolation using column values\nstore_items.interpolate(method = 'linear', axis = 0)\n\n# the original DataFrame is not modified. replace the NaN values\n# in place by setting inplace = True inside function\nstore_items.fillna(method = 'ffill', axis = 0, inplace = True)\nstore_items.interpolate(method = 'linear', axis = 0, inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### head, tail, describe, max, memory_usage","metadata":{}},{"cell_type":"code","source":"df.head()\ndf.tail()\ndf.describe()\n# prints max value in each column\ndf.max()\n\n# display the memory usage of a DataFrame\n# total usage\ndf.info()\n# usage by column\ndf.memory_usage()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### corr","metadata":{}},{"cell_type":"code","source":"# get the correlation between different columns\ndf.corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Groupby","metadata":{}},{"cell_type":"code","source":"# Groupby\ndata.groupby(['Year'])\ndata.groupby(['Year'])['Salary']\n\n# display the average salary per year\ndata.groupby(['Year'])['Salary'].mean()\n\n# display the total salary each employee received in all the years they worked for the company\ndata.groupby(['Name'])['Salary'].sum()\n\n# group the data by Year and by Department\ndata.groupby(['Year', 'Department'])['Salary'].sum()","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Replace Values","metadata":{}},{"cell_type":"code","source":"# Replace Values\ns = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\ns.map({'cat': 'kitten', 'dog': 'puppy'})\n# another e.g.\ndf['label'] = df['label'].map({'ham':0,'spam':1})","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading Files","metadata":{}},{"cell_type":"code","source":"# reading in a file from local computer or directly from a URL\n\n# various file formats that can be read in out wrote out\n‘’’\nFormat Type     Data Description      Reader           Writer\ntext                  CSV            read_csv          to_csv\ntext                 JSON            read_json         to_json\ntext                 HTML            read_html         to_html\ntext             Local clipboard  read_clipboard     to_clipboard\nbinary             MS Excel          read_excel        to_excel\nbinary            HDF5 Format        read_hdf           to_hdf\nbinary           Feather Format     read_feather      to_feather\nbinary              Msgpack         read_msgpack      to_msgpack\nbinary               Stata           read_stata        to_stata\nbinary                SAS             read_sas \nbinary        Python Pickle Format   read_pickle       to_pickle\nSQL                   SQL             read_sql          to_sql\nSQL             Google Big Query      read_gbq          to_gbq\n‘’’\n\n# to read about different types of files, and further functionality of reading in files, visit: http://pandas.pydata.org/pandas-docs/version/0.20/io.html\ndf = pd.read_csv('local_path/file.csv’)\ndf = pd.read_csv('https://file_path/file.csv')\n\n# when reading in tables, can specify separators, and note a column to be used as index separators can include tabs (“\\t”), commas(“,”), pipes (“|”), etc.\ndf = pd.read_table('https://file_path/file', sep='|', index_col='column_x')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Summarizing","metadata":{}},{"cell_type":"code","source":"# examine the df data\ndf           \n# print the first 30 and last 30 rows\ntype(df)     \n# DataFrame\ndf.head()    \n# print the first 5 rows\ndf.head(10)  \n# print the first 10 rows\ndf.tail()    \n# print the last 5 rows\ndf.index     \n# “the index” (aka “the labels”)\ndf.columns   \n# column names (which is “an index”)\ndf.dtypes    \n# data types of each column\ndf.shape\n# display only the number of rows\ndf.shape[0]\n# number of rows and columns\ndf.values    \n# underlying numpy array — df are stored as numpy arrays for effeciencies.\n\n# summarize (describe) the DataFrame\n# describe all numeric columns\ndf.describe()\n\n# describe all object columns\ndf.describe(include=['object'])\n\n# describe all columns\ndf.describe(include='all')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Working with Columns","metadata":{}},{"cell_type":"code","source":"# select a column\ndf['column_y']         \n# select one column\ntype(df['column_y'])   \n# determine datatype of column (e.g., Series)\ndf.column_y            \n# select one column using the DataFrame attribute — not effective if column names have spaces\n\n# summarize a Series/column\ndf.column_y.describe()   \n# describe a single column\ndf.column_z.mean()       \n# only calculate the mean\ndf[“column_z”].mean()    \n# alternate method for calculating mean\n\n# count the number of occurrences of each value\ndf.column_y.value_counts()   \n# most useful for categorical variables, but can also be used with numeric variables\n\n# filter df by one column, and print out values of another column\n# when using numeric values, no quotations\ndf[df.column_y == “string_value”].column_z\ndf[df.column_y == 20 ].column_z    \n \n# display the 3 most frequent occurances of column in ‘df’\ndf.column_y.value_counts()[0:3]","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filtering and Sorting","metadata":{}},{"cell_type":"code","source":"# boolean filtering: only show df with column_z < 20\nfilter_bool = df.column_z < 20    \n# create a Series of booleans…\ndf[filter_bool]                \n# …and use that Series to filter rows\ndf[filter_bool].describe()     \n# describes a data frame filtered by filter_bool\ndf[df.column_z < 20]           \n# or, combine into a single step\ndf[df.column_z < 20].column_x  \n# select one column from the filtered results\ndf[df[“column_z”] < 20].column_x     \n# alternate method \ndf[df.column_z < 20].column_x.value_counts()   \n# value_counts of resulting Series, can also use .mean(), etc. instead of .value_counts()\n\n# boolean filtering with multiple conditions; indexes are in square brackets, conditions are in parens\ndf[(df.column_z < 20) & (df.column_y==’string’)] \n# ampersand for AND condition \ndf[(df.column_z < 20) | (df.column_z > 60)] \n# pipe for OR condition\n\n# can also filter df using pandas.Series.isin \ndf[df.column_x.isin([“string_1”, “string_2”])]\n\n# display a cross-tabulation of two Series\npd.crosstab(df.column_x, df.column_y)\n\n# alternative syntax for boolean filtering (noted as “experimental” in the documentation)\ndf.query('column_z < 20') \n# df[df.column_z < 20]\ndf.query(\"column_z < 20 and column_y=='string'\")  \n# df[(df.column_z < 20) & (df.column_y==’string’)]\ndf.query('column_z < 20 or column_z > 60')        \n# df[(df.column_z < 20) | (df.column_z > 60)]","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sorting","metadata":{}},{"cell_type":"code","source":"# sorting\ndf.column_z.order()          \n# sort a column\ndf.sort_values(‘column_z’)   \n# sort a DataFrame by a single column\ndf.sort_values(‘column_z’, ascending=False)     \n# use descending order instead\n\n# Sort dataframe by multiple columns\ndf = df.sort([‘col1’,’col2',’col3'],ascending=[1,1,0])","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting Multiple Columns and Filtering Rows","metadata":{}},{"cell_type":"code","source":"# select multiple columns\nmy_cols = [‘column_x’, ‘column_y’]  \n# create a list of column names…\ndf[my_cols]                   \n# …and use that list to select columns\ndf[[‘column_x’, ‘column_y’]]  \n# or, combine into a single step — double brackets due to indexing a list.\n\n# use loc to select columns by name\ndf.loc[:, ‘column_x’]    \n# colon means “all rows”, then select one column\ndf.loc[:, [‘column_x’, ‘column_y’]]  \n# select two columns\ndf.loc[:, ‘column_x’:’column_y’]     \n# select a range of columns (i.e., selects all columns including first through last specified)\n\n# loc can also filter rows by “name” (the index)\ndf.loc[0, :]       \n# row 0, all columns\ndf.loc[0:2, :]     \n# rows 0/1/2, all columns\ndf.loc[0:2, ‘column_x’:’column_y’] \n# rows 0/1/2, range of columns\n\n# use iloc to filter rows and select columns by integer position\ndf.iloc[:, [0, 3]]     \n# all rows, columns in position 0/3\ndf.iloc[:, 0:4]        \n# all rows, columns in position 0/1/2/3\ndf.iloc[0:3, :]        \n# rows in position 0/1/2, all columns\n\n#filtering out and dropping rows based on condition (e.g., where column_x values are null)\ndrop_rows = df[df[“column_x”].isnull()]\nnew_df = df[~df.isin(drop_rows)].dropna(how=’all’)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Renaming, Adding, and Removing Columns","metadata":{}},{"cell_type":"code","source":"# rename one or more columns\ndf.rename(columns={‘original_column_1’:’column_x’, ‘original_column_2’:’column_y’}, inplace=True) \n# saves changes \n\n# replace all column names (in place)\nnew_cols = [‘column_x’, ‘column_y’, ‘column_z’]\ndf.columns = new_cols\n\n# replace all column names when reading the file\ndf = pd.read_csv(‘df.csv’, header=0, names=new_cols)\n\n# add a new column as a function of existing columns\ndf[‘new_column_1’] = df.column_x + df.column_y\ndf[‘new_column_2’] = df.column_x * 1000   \n#can create new columns without for loops\n\n# removing columns\ndf.drop(‘column_x’, axis=1)   \n# axis=0 for rows, 1 for columns — does not drop in place\ndf.drop([‘column_x’, ‘column_y’], axis=1, inplace=True) \n# drop multiple columns","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lower-case all DataFrame column names","metadata":{}},{"cell_type":"code","source":"# Lower-case all DataFrame column names\ndf.columns = map(str.lower, df.columns)\n\n# Even more fancy DataFrame column re-naming\n# lower-case all DataFrame column names (for example)\ndf.rename(columns=lambda x: x.split('.')[-1], inplace=True)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Values","metadata":{}},{"cell_type":"code","source":"# missing values are usually excluded by default\ndf.column_x.value_counts()             \n# excludes missing values\n\ndf.column_x.value_counts(dropna=False) \n# includes missing values\n\n# find missing values in a Series\ndf.column_x.isnull()  \n# True if missing\n\ndf.column_x.notnull() \n# True if not missing\n\n# use a boolean Series to filter DataFrame rows\ndf[df.column_x.isnull()]  \n# only show rows where column_x is missing\n\ndf[df.column_x.notnull()] \n# only show rows where column_x is not missing\n\n# understanding axes\ndf.sum()       \n# sums “down” the 0 axis (rows)\n\ndf.sum(axis=0) \n# equivalent (since axis=0 is the default)\n\ndf.sum(axis=1) \n# sums “across” the 1 axis (columns)\n\n# adding booleans\npd.Series([True, False, True])       \n# create a boolean Series\npd.Series([True, False, True]).sum() \n# converts False to 0 and True to 1\n\n# find missing values in a DataFrame\ndf.isnull() \n# DataFrame of booleans\ndf.isnull().sum() \n# count the missing values in each column\n\n# drop missing values\ndf.dropna(inplace=True)   \n# drop a row if ANY values are missing, defaults to rows, but can be applied to columns with axis=1\ndf.dropna(how=’all’, inplace=True)  \n# drop a row only if ALL values are missing\n\n# fill in missing values\ndf.column_x.fillna(value=’NA’, inplace=True) \n\n# fill in missing values with ‘NA’\n# value does not have to equal a string — can be set as some calculated value like df.column_x.mode(), or just a number like 0 \n\n# turn off the missing value filter\ndf = pd.read_csv(‘df.csv’, header=0, names=new_cols, na_filter=False)\n\n# Clean up missing values in multiple DataFrame columns\ndf = df.fillna({\n ‘col1’: ‘missing’,\n ‘col2’: ‘99.999’,\n ‘col3’: ‘999’,\n ‘col4’: ‘missing’,\n ‘col5’: ‘missing’,\n ‘col6’: ‘99’\n})\n\n# Concatenate two DataFrame columns into a new, single column - (useful when dealing with composite keys, for example)\ndf[‘newcol’] = df[‘col1’].map(str) + df[‘col2’].map(str)\n\n# Doing calculations with DataFrame columns that have missing values\n\n# In example below, swap in 0 for df[‘col1’] cells that contain null\ndf[‘new_col’] = np.where(pd.isnull(df[‘col1’]),0,df[‘col1’]) + df[‘col2’]","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Duplicated Values","metadata":{}},{"cell_type":"code","source":"# detecting duplicate rows\ndf.duplicated()\n\n# True if a row is identical to a previous row\ndf.duplicated().sum()\n\n# count of duplicates\ndf[df.duplicated()]\n\n# only show duplicates\ndf.drop_duplicates()\n\n# drop duplicate rows\ndf.column_z.duplicated()\n\n# check a single column for duplicates\ndf.duplicated([‘column_x’, ‘column_y’, ‘column_z’]).sum()  \n# specify columns for finding duplicates","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split-Apply-Combine\n<img src=\"http://i.imgur.com/yjNkiwL.png\">","metadata":{}},{"cell_type":"code","source":"# for each value in column_x, calculate the mean column_y \ndf.groupby(‘column_x’).column_y.mean()\n\n# for each value in column_x, count the number of occurrences\ndf.column_x.value_counts()\n\n# for each value in column_x, describe column_y\ndf.groupby(‘column_x’).column_y.describe()\n\n# similar, but outputs a DataFrame and can be customized\ndf.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’])\ndf.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’]).sort_values(‘mean’)\n\n# if you don’t specify a column to which the aggregation function should be applied, it will be applied to all numeric columns\ndf.groupby(‘column_x’).mean()\ndf.groupby(‘column_x’).describe()\n\n# can also groupby a list of columns, i.e., for each combination of column_x and column_y, calculate the mean column_z\ndf.groupby([“column_x”,”column_y”]).column_z.mean()\n\n#to take groupby results out of hierarchical index format (e.g., present as table), use .unstack() method\ndf.groupby(“column_x”).column_y.value_counts().unstack()\n\n#conversely, if you want to transform a table into a hierarchical index, use the .stack() method\ndf.stack()","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merging and Concatenating Dataframes","metadata":{}},{"cell_type":"code","source":"#concatenating two dfs together (just smooshes them together, does not pair them in any meaningful way) - axis=1 concats df2 to right side of df1; axis=0 concats df2 to bottom of df1\nnew_df = pd.concat([df1, df2], axis=1)\n\n#merging dfs based on paired columns; columns do not need to have same name, but should match values; left_on column comes from df1, right_on column comes from df2\nnew_df = pd.merge(df1, df2, left_on=’column_x’, right_on=’column_y’)\n\n#can also merge slices of dfs together, though slices need to include columns used for merging\nnew_df = pd.merge(df1[[‘column_x1’, ‘column_x2’]], df2, left_on=’column_x2', right_on=’column_y’)\n\n#merging two dataframes based on shared index values (left is df1, right is df2)\nnew_df = pd.merge(df1, df2, left_index=True, right_index=True)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Frequently Used Features","metadata":{}},{"cell_type":"markdown","source":"#### map existing values to a different set of values","metadata":{}},{"cell_type":"code","source":"df[‘column_x’] = df.column_y.map({‘F’:0, ‘M’:1})","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### encode strings as integer values (automatically starts at 0)","metadata":{}},{"cell_type":"code","source":"df[‘column_x_num’] = df.column_x.factorize()[0]","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### determine unique values in a column","metadata":{}},{"cell_type":"code","source":"df.column_x.nunique() ","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### count the number of unique values","metadata":{}},{"cell_type":"code","source":"df.column_x.unique()    \n# returns the unique values","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### replace all instances of a value in a column (must match entire value)","metadata":{}},{"cell_type":"code","source":"df.column_y.replace(‘old_string’, ‘new_string’, inplace=True)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### alter values in one column based on values in another column","metadata":{}},{"cell_type":"code","source":"# changes occur in place\n# can use either .loc or .ix methods\ndf.loc[df[“column_x”] == 5, “column_y”] = 1\ndf.ix[df.column_x == “string_value”, “column_y”] = “new_string_value”","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### transpose data frame (i.e. rows become columns, columns become rows)","metadata":{}},{"cell_type":"code","source":"df.T","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### string methods are accessed via ‘str’","metadata":{}},{"cell_type":"code","source":"df.column_y.str.upper()","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### converts to uppercase","metadata":{}},{"cell_type":"code","source":"df.column_y.str.contains(‘value’, na=’False’) \n# checks for a substring, returns boolean series","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### convert a string to the datetime_column format","metadata":{}},{"cell_type":"code","source":"df[‘time_column’] = pd.to_datetime_column(df.time_column)\ndf.time_column.dt.hour ","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### datetime_column format exposes convenient attributes","metadata":{}},{"cell_type":"code","source":"(df.time_column.max() — df.time_column.min()).days","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### boolean filtering with datetime_column format","metadata":{}},{"cell_type":"code","source":"df[df.time_column > pd.datetime_column(2014, 1, 1)]   \n# also allows you to do datetime_column “math”","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### setting and then removing an index, resetting index can help remove hierarchical indexes while preserving the table in its basic structure","metadata":{}},{"cell_type":"code","source":"df.set_index(‘time_column’, inplace=True)\ndf.reset_index(inplace=True)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### sort a column by its index","metadata":{}},{"cell_type":"code","source":"df.column_y.value_counts().sort_index()","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### change the data type of a column","metadata":{}},{"cell_type":"code","source":"df[‘column_x’] = df.column_x.astype(‘float’)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### change the data type of a column when reading in a file","metadata":{}},{"cell_type":"code","source":"pd.read_csv(‘df.csv’, dtype={‘column_x’:float})","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### create dummy variables for ‘column_x’ and exclude first dummy column","metadata":{}},{"cell_type":"code","source":"column_x_dummies = pd.get_dummies(df.column_x).iloc[:, 1:]","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### concatenate two DataFrames (axis=0 for rows, axis=1 for columns)","metadata":{}},{"cell_type":"code","source":"df = pd.concat([df, column_x_dummies], axis=1)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loop through rows in a DataFrame","metadata":{}},{"cell_type":"code","source":"# Loop through rows in a DataFrame\nfor index, row in df.iterrows():\n print index, row[‘column_x’]\n\n# Much faster way to loop through DataFrame rows if you can work with tuples\nfor row in df.itertuples():\n print(row)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get rid of non-numeric values throughout a DataFrame","metadata":{}},{"cell_type":"code","source":"for col in df.columns.values:\n df[col] = df[col].replace(‘[⁰-9]+.-’, ‘’, regex=True)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Change all NaNs to None (useful before loading to a db)","metadata":{}},{"cell_type":"code","source":"df = df.where((pd.notnull(df)), None)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split delimited values in a DataFrame column into two new columns","metadata":{}},{"cell_type":"code","source":"df[‘new_col1’], df[‘new_col2’] = zip(*df[‘original_col’].apply(lambda x: x.split(‘: ‘, 1)))","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Collapse hierarchical column indexes","metadata":{}},{"cell_type":"code","source":"df.columns = df.columns.get_level_values(0)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### change a Series to the ‘category’ data type (reduces memory usage and increases performance)","metadata":{}},{"cell_type":"code","source":"df[‘column_y’] = df.column_y.astype(‘category’)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### temporarily define a new column as a function of existing columns","metadata":{}},{"cell_type":"code","source":"df.assign(new_column = df.column_x + df.spirit + df.column_y)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## If you like this kernel, please give it an upvote. Thank you! :)","metadata":{}}]}